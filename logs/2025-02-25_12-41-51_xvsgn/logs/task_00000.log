2025-02-25 12:41:51.787 | INFO     | datatrove.utils.logging:add_task_logger:58 - Launching pipeline for rank=0
2025-02-25 12:41:51.787 | INFO     | datatrove.utils.logging:log_pipeline:90 - 
--- 🛠️ PIPELINE 🛠
📖 - READER: 📒 Parquet
<__main__.SizeLimitFilter object at 0x7f14ea438f50>
💽 - WRITER: 📒 Parquet
2025-02-25 12:41:53.057 | INFO     | datatrove.pipeline.readers.base:read_files_shard:191 - Reading input file 000_00000.parquet, 1/2
2025-02-25 12:41:54.805 | ERROR    | datatrove.executor.base:_run_for_rank:108 - '>=' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):

  File "<string>", line 1, in <module>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/forkserver.py", line 273, in main
    code = _serve_one(child_r, fds,
           │          │        └ [10, 11, 12, 13, 14, 15]
           │          └ 8
           └ <function _serve_one at 0x7f14ebc2c2c0>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/forkserver.py", line 312, in _serve_one
    code = spawn._main(child_r, parent_sentinel)
           │     │     │        └ 4
           │     │     └ 8
           │     └ <function _main at 0x7f14ebc1b420>
           └ <module 'multiprocess.spawn' from '/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/spawn.py'>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
           │    │          └ 4
           │    └ <function BaseProcess._bootstrap at 0x7f14ec198b80>
           └ <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/process.py", line 314, in _bootstrap
    self.run()
    │    └ <function BaseProcess.run at 0x7f14ec1980e0>
    └ <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
    │    │        │    └ (<multiprocess.queues.SimpleQueue object at 0x7f14ea606650>, <multiprocess.queues.SimpleQueue object at 0x7f14ea430e90>, None...
    │    │        └ <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
    │    └ <function worker at 0x7f14ea4284a0>
    └ <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    │     │       └ {}
                    │     └ (0,)
                    └ functools.partial(<bound method LocalPipelineExecutor._launch_run_for_rank of <datatrove.executor.local.LocalPipelineExecutor...
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/datatrove/executor/local.py", line 76, in _launch_run_for_rank
    return self._run_for_rank(rank, local_rank)
           │    │             │     └ 0
           │    │             └ 0
           │    └ <function PipelineExecutor._run_for_rank at 0x7f14ea557560>
           └ <datatrove.executor.local.LocalPipelineExecutor object at 0x7f14ea6063d0>
> File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/datatrove/executor/base.py", line 90, in _run_for_rank
    pipelined_data = pipeline_step(pipelined_data, rank, self.world_size)
                     │             │               │     │    └ <property object at 0x7f14ebc403b0>
                     │             │               │     └ <datatrove.executor.local.LocalPipelineExecutor object at 0x7f14ea6063d0>
                     │             │               └ 0
                     │             └ <generator object BaseDiskReader.run at 0x7f14ec33adf0>
                     └ <__main__.SizeLimitFilter object at 0x7f14ea438f50>

  File "/home/andbu/Documents/trustllm/TechStack/LiULLM/JUWELS/WP2/data/get_swed_fineweb.py", line 34, in __call__
    doc = next(doc)
               └ <generator object BaseDiskReader.run at 0x7f14ec33adf0>

  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/datatrove/pipeline/readers/base.py", line 235, in run
    for doc in self.read_files_shard(files_shard):
               │    │                └ ['000_00000.parquet', '003_00001.parquet']
               │    └ <function BaseDiskReader.read_files_shard at 0x7f14ea568cc0>
               └ 📖 - READER: 📒 Parquet
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/datatrove/pipeline/readers/base.py", line 198, in read_files_shard
    if self.limit != -1 and li >= self.limit:
       │    │               │     │    └ None
       │    │               │     └ 📖 - READER: 📒 Parquet
       │    │               └ 0
       │    └ None
       └ 📖 - READER: 📒 Parquet

TypeError: '>=' not supported between instances of 'int' and 'NoneType'
