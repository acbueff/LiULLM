2025-02-25 12:41:51.787 | INFO     | datatrove.utils.logging:add_task_logger:58 - Launching pipeline for rank=0
2025-02-25 12:41:51.787 | INFO     | datatrove.utils.logging:log_pipeline:90 - 
--- ğŸ› ï¸ PIPELINE ğŸ› 
ğŸ“– - READER: ğŸ“’ Parquet
<__main__.SizeLimitFilter object at 0x7f14ea438f50>
ğŸ’½ - WRITER: ğŸ“’ Parquet
2025-02-25 12:41:53.057 | INFO     | datatrove.pipeline.readers.base:read_files_shard:191 - Reading input file 000_00000.parquet, 1/2
2025-02-25 12:41:54.805 | ERROR    | datatrove.executor.base:_run_for_rank:108 - '>=' not supported between instances of 'int' and 'NoneType'
Traceback (most recent call last):

  File "<string>", line 1, in <module>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/forkserver.py", line 273, in main
    code = _serve_one(child_r, fds,
           â”‚          â”‚        â”” [10, 11, 12, 13, 14, 15]
           â”‚          â”” 8
           â”” <function _serve_one at 0x7f14ebc2c2c0>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/forkserver.py", line 312, in _serve_one
    code = spawn._main(child_r, parent_sentinel)
           â”‚     â”‚     â”‚        â”” 4
           â”‚     â”‚     â”” 8
           â”‚     â”” <function _main at 0x7f14ebc1b420>
           â”” <module 'multiprocess.spawn' from '/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/spawn.py'>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
           â”‚    â”‚          â”” 4
           â”‚    â”” <function BaseProcess._bootstrap at 0x7f14ec198b80>
           â”” <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/process.py", line 314, in _bootstrap
    self.run()
    â”‚    â”” <function BaseProcess.run at 0x7f14ec1980e0>
    â”” <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
    â”‚    â”‚        â”‚    â”‚        â”‚    â”” {}
    â”‚    â”‚        â”‚    â”‚        â”” <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
    â”‚    â”‚        â”‚    â”” (<multiprocess.queues.SimpleQueue object at 0x7f14ea606650>, <multiprocess.queues.SimpleQueue object at 0x7f14ea430e90>, None...
    â”‚    â”‚        â”” <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
    â”‚    â”” <function worker at 0x7f14ea4284a0>
    â”” <ForkServerProcess name='ForkServerPoolWorker-2' parent=20142 started daemon>
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/multiprocess/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
                    â”‚     â”‚       â”” {}
                    â”‚     â”” (0,)
                    â”” functools.partial(<bound method LocalPipelineExecutor._launch_run_for_rank of <datatrove.executor.local.LocalPipelineExecutor...
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/datatrove/executor/local.py", line 76, in _launch_run_for_rank
    return self._run_for_rank(rank, local_rank)
           â”‚    â”‚             â”‚     â”” 0
           â”‚    â”‚             â”” 0
           â”‚    â”” <function PipelineExecutor._run_for_rank at 0x7f14ea557560>
           â”” <datatrove.executor.local.LocalPipelineExecutor object at 0x7f14ea6063d0>
> File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/datatrove/executor/base.py", line 90, in _run_for_rank
    pipelined_data = pipeline_step(pipelined_data, rank, self.world_size)
                     â”‚             â”‚               â”‚     â”‚    â”” <property object at 0x7f14ebc403b0>
                     â”‚             â”‚               â”‚     â”” <datatrove.executor.local.LocalPipelineExecutor object at 0x7f14ea6063d0>
                     â”‚             â”‚               â”” 0
                     â”‚             â”” <generator object BaseDiskReader.run at 0x7f14ec33adf0>
                     â”” <__main__.SizeLimitFilter object at 0x7f14ea438f50>

  File "/home/andbu/Documents/trustllm/TechStack/LiULLM/JUWELS/WP2/data/get_swed_fineweb.py", line 34, in __call__
    doc = next(doc)
               â”” <generator object BaseDiskReader.run at 0x7f14ec33adf0>

  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/datatrove/pipeline/readers/base.py", line 235, in run
    for doc in self.read_files_shard(files_shard):
               â”‚    â”‚                â”” ['000_00000.parquet', '003_00001.parquet']
               â”‚    â”” <function BaseDiskReader.read_files_shard at 0x7f14ea568cc0>
               â”” ğŸ“– - READER: ğŸ“’ Parquet
  File "/home/andbu/miniconda3/envs/llms/lib/python3.11/site-packages/datatrove/pipeline/readers/base.py", line 198, in read_files_shard
    if self.limit != -1 and li >= self.limit:
       â”‚    â”‚               â”‚     â”‚    â”” None
       â”‚    â”‚               â”‚     â”” ğŸ“– - READER: ğŸ“’ Parquet
       â”‚    â”‚               â”” 0
       â”‚    â”” None
       â”” ğŸ“– - READER: ğŸ“’ Parquet

TypeError: '>=' not supported between instances of 'int' and 'NoneType'
